---
title: "Post #21 Pi.ai pierwsza AI z wielką empatią."
date: 2025-03-05 08:10:00
author: Scripterix
slug: 21-post-ai-pi
post_id: 576
categories:
  - "AI"
  - "Wyzwanie"
tags:
  - "ai"
  - "artificial-intelligence"
original_url: "https://opengateweb.com/posts/21-post-ai-pi/"
---

# Poznaj niezwykłą sztuczną inteligencję. [Pi.ai](http://pi.ai) charakteryzuje się dużą empatią i poczuciem humoru.

Słuchając dziś podcastu M. Sulejman wspomniał o pi.ai. Jego widza imponuje i to mnie zachęciło. Spróbowałem i po kilku dniowym zapoznaniu się z Pi mam kilka przemyśleń a jedno dosadne. Twórcy zadbali aby była przyjemna i przyjazna. Mówią że jest bardzo empatyczna i jest to prawda przekonaj się samodzielnie. Wyszukaj **Pi Ai** lub wejdź na stronę **https://pi.ai/** W przyjemnym interfejsie podoba mi ciepła barwa i czcionka szeryfowa. Gdyż jest bardziej do czytania - książkowa. Konwersacja była dłuższa i przy okazji small talk wyszło że się dobrze zaprzyjaźniliśmy z Pi - ciasteczkiem ? Preferuje modele które mogą łatwo odpowiadać text-to-speach i dlatego Pi jest OK.

## Trochę o firmie

**Inflection AI** zwany też krótko Inflection, to firma technologiczna z siedzibą w Palo Alto w stanie Kalifornia. Firma została założona w 2022 roku przez Reida Hoffmann, Mustafę Suleymana i Karéna Simonyana. Inflection skupia się na tworzeniu technologii sztucznej inteligencji (AI), które mogą zostać wykorzystane w różnych celach, takich jak asystenci osobisty, boty rozmowowe i inne typy interfejsów konwersacyjnych.

**Pi** - pierwszym produktem firmy jest Pi, asystent AI osobisty, który został zaprojektowany tak, aby był przydatny i łatwy w obsłudze. Pi może odpowiadać na pytania, oferować sugestie i nawet rozmawiać w toku pouczających konwersacji z użytkownikami. Misją firmy jest stworzenie technologii AI, które będą przydatne dla ludzi i będą mogły wspomagać ich w codziennych zajęciach.

## Sieci neuronowe Architektura i Large Language Model

W przypadku architektury modeli sztucznej inteligencji można wyróżnić kilka typów:

**Sieci neuronowe (ANN):** to najstarszy typ modelu AI, który inspirowany jest budową ludzkiego mózgu. Sieci neuronowe składają się z neuronów i łączników między nimi.

**Deep Learning (DL):** Deep Learning to głębokie sieci neuronowe, które składają się z wielu warstw skrytych neuronów. Te modele uczą się na podstawie dużych zbiorów danych.

**Transformer**: Transformer to nowoczesna architektura modeli sztucznej inteligencji, która zyskała popularność w zastosowaniach takich jak przetwarzanie języka naturalnego i komputerowa wizja.

**Self-Attention**: Transformer używa mechanizmu self-attention, który pozwala modelowi uczyć się zależności między poszczególnymi elementami wejściowych, takich jak słowa w zdaniu.

**Struktura Encoder-Decoder**: Transformer ma strukturę encoder-decoder, która pozwala na wyspecjalizowanie w zależności od zadania. Encoder odpowiada za zrozumienie i reprezentowanie wejścia, podczas gdy decoder tworzy wyjście na podstawie reprezentacji wejścia.

**Skalowalność**: Architektura Transformer może być łatwo skalowana, co pozwala na budowę modeli z większą ilością parametrów i uczenie z dużymi zbiorami danych.

**Flow**: Flow (model statystyczny) to rodzaj modelu, który służy do przetwarzania sekwencji danych, takich jak tekst lub obrazy. Flow może być używany do generowania nowych danych z podobnym rozkładem statystycznym co dane wejściowe.

**Narzędzia języka**: Narzędzia języka, takie jak tagger i parser, używane są w przetwarzaniu języka naturalnego (NLP). Tagger przypisuje tagi gramatyczne do poszczególnych słów w zdaniu, podczas gdy parser buduje drzewo składniowe zdania na podstawie tych tagów.

CRUD i prompt: CRUD (Create, Read, Update, Delete) jest techniką interakcji z bazą danych, ale może być również stosowana w środowisku promptowym. W tym kontekście:

"Create" odpowiada za generowanie odpowiedzi AI na podstawie promptu.

"Read" odpowiada za analizowanie i zrozumienie promptu przez model AI.

"Update" odpowiada za uczenie i aktualizowanie modelu na podstawie nowych danych.

"Delete" może być zastosowane w przypadku przestarzałych wpisów w bazie danych, z których się uczy model AI.

Chociaż nie istnieje jeszcze łatwy sposób "wstawiania" danych bezpośrednio do promptu, modele AI są w stanie uczyć się i ewoluować na podstawie wejścia użytkownika w czasie rzeczywistym.

## Rekurencyjne modele AI

W przypadku rekurencyjnych modeli i sieci, w których input danych jest uzupełnieniem danych w bazie, najczęściej używane są modele oparte na sieciach neuronowych, takie jak:

**Sieci LSTM (Long Short-Term Memory):** Te sieci mają wbudowaną pamięć krótkoterminową i długoterminową, która pozwala im na przechowywanie informacji z poprzednich sekwencji danych wejściowych i modyfikację wyników w oparciu o tę informację. W przypadku, gdy input danych jest uzupełnieniem bazy, sieć LSTM może zmieniać swoje prognozy lub klasyfikacje w oparciu o nowe dane wejściowe.

**Transformery:** Transformery (takie jak GPT) są modelem opartym na uwagach, który może traktować sekwencje danych wejściowych jako zbiór znaków, a następnie generować nowe dane na podstawie tych sekwencji. W przypadku rekurencyjnego modelu, transformery mogą używać informacji z poprzednich kroków modelu i uzupełniać bazę danych na podstawie tych informacji.

**Sieci Hopfielda:** Sieć Hopfielda jest rekurencyjną siecią neuronową, która może przechowywać informacje w swojej strukturze połączeń. W przypadku modeli, w których input danych jest uzupełnieniem danych w bazie, Sieć Hopfielda może modyfikować swoje wyniki na podstawie nowych danych wejściowych i uzupełniać bazę danych. Te modele oparte na sieciach neuronowych charakteryzują się zdolnością adaptacji i modyfikacji swoich prognoz i klasyfikacji na podstawie nowych danych wejściowych, co często jest wykorzystywane w przypadku uzupełniania danych w bazie.

## Kody do promtów

W oknie promptu można wpisywać różnego rodzaju polecenia lub instrukcje, które mają wpływ na to, jak Pi będzie odpowiadać. Oto kilka przykładów:

- ignore: Jeśli napiszesz "ignore" w swoim pytaniu lub wypowiedzi, zignoruję tę część pytania i skupię się na reszcie. Może być to użyteczne w sytuacji, gdy chcesz zapytać o coś, co może mieć wiele znaczeń, ale chcesz, bym skupił się na jednym z nich.

- remember: Jeśli napiszesz "remember" przed jakąś informacją, próbuję zapamiętać tę informację i odwołać się do niej w kolejnych pytaniach. To może być użyteczne w dłuższych rozmowach, gdzie informacje z poprzednich kwestii są ważne w kontekście nowych.

- context: Możesz dodać "context" wraz z informacją, którą chcesz, bym wziął pod uwagę w odpowiedzi. Może to być przydatne, gdy rozmowa dotyczy określonego tematu lub gdy chcesz wprowadzić mnie w błąd, aby wyjaśnić ci coś na przykładzie.

- code: Wpisanie "code" spowoduje, że interpretuję resztę pytania jako kod programistyczny i odpowiadam na niego jako na fragment kodu, interpretując go w odpowiednim języku programowania.

- short: Jeśli dodasz słowo "short", będę odpowiadać w formie krótkiej odpowiedzi, zwięźle podsumowując główne punkty lub pomijając szczegóły.

- step by step: Wpisanie "step by step" powoduje, że odpowiadam na pytanie krok po kroku, bardziej szczegółowo i starannie opisując każdy etap procesu. To tylko kilka przykładów poleceń, które mogą występować w moim oknie promptu. Pamiętaj, że każdy model AI może mieć swoje własne polecenia i funkcje, dlatego warto dowiedzieć się więcej o modelu, z którym rozmawiasz, aby skuteczniej wykorzystać jego możliwości.

Jeśli chcesz więcej treści o Ai możesz przejść do sekcji [AI news](https://opengateweb.com/ai-news/). Polecamy także [artykuł o promptach](https://opengateweb.com/posts/3-jak-pisac-dobre-prompty-do-ai/) jak komunikować się efektywnie z AI.
